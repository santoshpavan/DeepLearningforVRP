{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "0R6chiOssBaj",
    "outputId": "42306fe1-4642-4702-a61f-1efb41333fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"vrp_dqn.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1iothquIlGtKKte5KIxO-YCKzXnZGjbK-\n",
    "\"\"\"\n",
    "# !pip install tsplib95\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import tsplib95\n",
    "import networkx as nx\n",
    "import pickle\n",
    "\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import tensorflow\n",
    "if tensorflow.test.gpu_device_name():\n",
    "    print('Default GPU Device: {}'.format(tensorflow.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Activation, Flatten\n",
    "from tensorflow.python.keras import Sequential\n",
    "# from tensorflow.python.keras.optimizers import SGD\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from collections import deque\n",
    "\n",
    "import io # to save the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZA_bOlXdsHOh",
    "outputId": "095084ca-9e58-4121-e0cc-117ee20db7ca"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y9iofX44xw0s"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2https://stackoverflow.com/questions/57301698/how-to-change-a-learning-rate-for-adam-in-tf2\n",
    "class LearningRateReducerCb(tensorflow.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # old_lr = self.model.optimizer.lr.read_value()\n",
    "        # new_lr = old_lr * 0.99\n",
    "        new_lr = 0.1\n",
    "        # print(\"\\nEpoch: {}. Reducing Learning Rate from {} to {}\".format(epoch, old_lr, new_lr))\n",
    "        self.model.optimizer.lr.assign(new_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R8NT6EoJDsQ4"
   },
   "outputs": [],
   "source": [
    "# 6. Define the movement restriction of the truck.\n",
    "class Truck:\n",
    "    def __init__(self, capacity, id, color):\n",
    "        self.id = id\n",
    "        self.color = color\n",
    "        self.path = [] #this has the list of nodes it has visited\n",
    "        self.max_truck_capacity = copy.deepcopy(capacity) #the max capacity\n",
    "        self.capacity = copy.deepcopy(capacity)\n",
    "        #self.visit_depo()\n",
    "        self.prev_node = None\n",
    "        self.node = 1 #starts from the depo\n",
    "\n",
    "    def action(self, choice):\n",
    "        # the number of choice of actions are the number of nodes-1\n",
    "        # the choice to be taken depends on the demands - penalty based\n",
    "        # the choice number is the same as the node number\n",
    "        # it is not a choice if the demand is 0 - changing this to penalty\n",
    "        #!! Want the system to learn instead\n",
    "        # if self.capacity == 0:\n",
    "        #     self.visit_depo()\n",
    "        self.move(choice)\n",
    "\n",
    "    def move(self, to_node_value):\n",
    "        # node_list_copy = copy.deepcopy(node_list)\n",
    "        # node_list_copy.remove(1)\n",
    "        # select a random node to go to\n",
    "        #if not to_node_value: #to_node_value is False by default\n",
    "        #    to_node_value = random.choice(self.node_list)\n",
    "        if to_node_value == 1:\n",
    "            self.visit_depo()\n",
    "        self.prev_node = self.node\n",
    "        self.node = to_node_value\n",
    "        self.path.append(to_node_value)\n",
    "        # when invoked update the demand of the node\n",
    "        # update the demand of the node\n",
    "\n",
    "    def visit_depo(self):\n",
    "        self.prev_node = self.node\n",
    "        self.node = 1 #here it is 1\n",
    "        self.capacity = copy.deepcopy(self.max_truck_capacity) #truck capacity reset\n",
    "        self.path.append(1)\n",
    "    \n",
    "    #def path(self, node_value):\n",
    "    #    self.path.append(node_value)\n",
    "\n",
    "    # def get_node(self):\n",
    "    #     return self.node\n",
    "\n",
    "    \n",
    "    # def get_capacity(self):\n",
    "    #     return self.capacity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjYDwT6rD15Q"
   },
   "outputs": [],
   "source": [
    "class VRPEnvironment:\n",
    "    # environment related constants\n",
    "    #https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.figure.html\n",
    "    #observation_space = (640,480,3)\n",
    "    # observation_space = (100,100,3)\n",
    "    observation_space = (10,10,3)\n",
    "    # penalty and rewards\n",
    "    non_positive_capacity_penalty = 100\n",
    "    zero_demand_penalty = 100 #truck goes to a zero demand node - except 1\n",
    "    # ignore the failing task penalty as the episode will end only when...\n",
    "    # all the demands are satisfied i.e. task will always be success...\n",
    "    # The penalty of the achievement needs to go down.\n",
    "    failing_task_penalty = 100 #trucks fail to complete the task\n",
    "    completion_reward = 5000 #trucks complete the task\n",
    "    hopping_incentive_penalty = 1000\n",
    "    # visit_correct_node_reward = 100\n",
    "    # exploration settings\n",
    "    permitted_path_length = 30\n",
    "    epsilon = 1\n",
    "    epsilon_decay = 0.999#changing this from 0.999\n",
    "    min_epsilon = 0.001 #0.001\n",
    "    no_of_episodes = 30_000\n",
    "    # from 0 to 0.5 difference is small so using 1 first\n",
    "    truck_colors = {\n",
    "        1:(0,0,1),\n",
    "        2:(0,1,0),\n",
    "        3:(1,0,0),\n",
    "        4:(0,0.5,0.5),\n",
    "        5:(0.5,0,0.5),\n",
    "        6:(0.5,0.5,0),\n",
    "        7:(0.5,0.5,0.5),\n",
    "        8:(0.5,0.5,1),\n",
    "        9:(0.5,1,0.5),\n",
    "        10:(1,0.5,0.5)\n",
    "    }\n",
    "    return_images = True\n",
    "    image_size = 100\n",
    "\n",
    "    def __init__(self):\n",
    "        # 1. Extract the tsplib95 file problem\n",
    "        # self.problem = tsplib95.load_problem('/content/drive/My Drive/HW Assignments/Sem 2/ADBI/Vrp-All/A/A-n32-k5.vrp')\n",
    "        # self.problem = tsplib95.load_problem('/content/drive/My Drive/HW Assignments/Sem 2/ADBI/Vrp-All/_singleTruck/A-n32-k5_2.vrp')\n",
    "        self.problem = tsplib95.load_problem('Vrp-All/_singleTruck/A-n32-k5_2.vrp')        \n",
    "        # 2. Create a networkx graph out of the problem. //will be plotting this\n",
    "        self.nx_graph = self.problem.get_graph()\n",
    "        self.edge_list = list(self.problem.get_edges()) #[(,)]\n",
    "        self.node_positions = self.problem.node_coords #dict\n",
    "        # the list of nodes\n",
    "        self.node_list = list(self.problem.get_nodes())\n",
    "        self.action_space = len(self.node_list) #the number of choices including staying put\n",
    "        # the depot location\n",
    "        self.depot_location = 1\n",
    "        # assigning the default color of the nodes to be black\n",
    "        # node_color_values = [(0,0,0) for i in range(len(node_list))]\n",
    "        # reseting the environment when initialized\n",
    "        self.reset_environment()\n",
    "        \n",
    "    def reset_environment(self):\n",
    "        # creating the Trucks\n",
    "        # 4. Extract the necessary data about the trucks. //no of trucks, depot_section, capacity\n",
    "        self.node_demands = copy.deepcopy(self.problem.demands)\n",
    "        truck_capacity = copy.deepcopy(self.problem.capacity)\n",
    "        # trying hardcoding for now\n",
    "        self.truck = Truck(truck_capacity, 1, self.truck_colors.get(3))\n",
    "\n",
    "        self.episode_step = 0\n",
    "\n",
    "        if self.return_images:\n",
    "            observation = np.array(self.get_image())\n",
    "        \n",
    "        # resetting the environment reward value\n",
    "        # self.reward = 0\n",
    "        # there is no else case as we need always need the image for CNN\n",
    "        return observation\n",
    "\n",
    "    # def calculate_move_penalty(self, source_node, dest_node):\n",
    "    #     return self.problem.wfunc(source_node, dest_node) #the weight of the edge\n",
    "\n",
    "    # change the demand of the node when visited\n",
    "    def change_demand(self, node):\n",
    "        self.node_demands[node] = 0\n",
    "\n",
    "    def step(self, action):\n",
    "        self.episode_step += 1\n",
    "        # moving the trucks for the action\n",
    "        self.truck.action(action)\n",
    "        #print(\"action=\"+str(action)+\"\\n++++++\")\n",
    "        self.truck.capacity -= self.node_demands.get(action)\n",
    "        self.change_demand(action)\n",
    "        # print(self.truck.capacity)\n",
    "        # other truck actions\n",
    "\n",
    "        if self.return_images:\n",
    "            new_observation = np.array(self.get_image())\n",
    "        # there is no else case as the return image is always true\n",
    "\n",
    "        # assinging the rewards and penalties\n",
    "        self.reward = 0\n",
    "        # checking if the demands have been satisfied\n",
    "        completed = False\n",
    "        if sum(list(self.node_demands.values())) == 0:\n",
    "            print(\"\\n***Satisfied***\")\n",
    "            # print(self.node_demands)\n",
    "            completed = True\n",
    "            self.reward = self.completion_reward\n",
    "        else:\n",
    "            # rewards for other trucks\n",
    "            # print(\"before\"+str(self.reward))\n",
    "            self.node_penalty(self.truck) #other penalties\n",
    "            self.movement_penalty(self.truck) #edge weight\n",
    "            # print(\"after\"+str(self.reward))\n",
    "            # penalties for other trucks\n",
    "        done = False\n",
    "        if self.reward == self.completion_reward or len(self.truck.path) >= self.permitted_path_length:\n",
    "        # if self.reward == self.completion_reward:\n",
    "            done = True\n",
    "            if sum(list(self.node_demands.values())) > 0:\n",
    "                self.reward -= self.failing_task_penalty\n",
    "\n",
    "        return new_observation, self.reward, done, completed\n",
    "\n",
    "    def node_penalty(self, truck):\n",
    "        if self.node_demands[truck.node] == 0:\n",
    "            if (truck.node == 1 and truck.capacity == truck.max_truck_capacity) or truck.node!=1:\n",
    "                self.reward -= self.zero_demand_penalty\n",
    "\n",
    "        if self.truck.capacity <= 0:\n",
    "            self.reward -= self.non_positive_capacity_penalty\n",
    "        # return self.reward\n",
    "\n",
    "    def movement_penalty(self, truck):\n",
    "        #print(self.truck.path)\n",
    "        #print(\"-------\")\n",
    "        if truck.prev_node: #else it's 0\n",
    "            source_node = truck.prev_node\n",
    "            destination_node = truck.node\n",
    "            if source_node == destination_node: #if truck stays at the same place\n",
    "                self.reward -= self.hopping_incentive_penalty\n",
    "            self.reward -= self.problem.wfunc(source_node, destination_node)\n",
    "            # return self.problem.wfunc(source_node, destination_node)\n",
    "        # else:\n",
    "        #     source_node = truck.node\n",
    "        #     destination_node = truck.node\n",
    "        #     return 0\n",
    "    # \"\"\"\n",
    "    def get_image(self):\n",
    "        # the initiated rgb image of the given size. image_size = 100\n",
    "        env = np.zeros((self.image_size, self.image_size, 3), dtype=np.uint8)\n",
    "        for node in self.node_positions.keys():\n",
    "            node_coods = self.node_positions.get(node)\n",
    "            env[int(node_coods[0])][int(node_coods[1])] = (255,255,255)\n",
    "        if self.truck.path: #if there are elements in the path\n",
    "            for visited_node in set(self.truck.path):\n",
    "                node_coods = self.node_positions.get(visited_node)\n",
    "                #print(node_coods)\n",
    "                #print(visited_node)\n",
    "                #print(self.truck.path)\n",
    "                #print(len(env))\n",
    "                #print(\"--------\")\n",
    "                #try: #HAVING 0 HERE WAS CAUSING ERRORS! IGNORING 0 FOR NOW- STUPID\n",
    "                env[int(node_coods[0])][int(node_coods[1])] = (255,0,0)\n",
    "                #except:\n",
    "                    #print(node_coods)\n",
    "                    #print(visited_node)\n",
    "                    #print(self.truck.path)\n",
    "                    #print(len(env))\n",
    "                    #print(\"--------\")\n",
    "        img = Image.fromarray(env, 'RGB')\n",
    "        # trying to reduce to size to decrease the time taken\n",
    "        img = img.resize((10,10))\n",
    "        return img\n",
    "\n",
    "    def render(self):\n",
    "        img = self.get_image()\n",
    "        img = img.resize((500,500))\n",
    "        cv2.imshow(\"image\", np.array(img))\n",
    "        cv2.waitKey(1)\n",
    "    \"\"\"\n",
    "    def get_image(self):\n",
    "        fig,ax = plt.subplots()\n",
    "        node_color_values = [(0,0,1) for i in range(len(self.node_list))]\n",
    "        # ax.clear()\n",
    "        if not self.truck.path: #if it is not empty\n",
    "            for i in self.truck.path:\n",
    "                node_color_values[i] = (1,0,0)\n",
    "        image_io = io.BytesIO()\n",
    "        #edge color is white to ignore it\n",
    "        nx.draw(self.nx_graph, pos=self.node_positions, with_labels=False, node_color=node_color_values, node_size=20, edge_color=(1,1,1))\n",
    "        fig.savefig(image_io, dpi=5)\n",
    "        image = Image.open(image_io)\n",
    "        image = image.resize((10,10))\n",
    "        image.close() #keeping it open consumes a lot of memory\n",
    "        return image\n",
    "\n",
    "    def render(self):\n",
    "        image = self.get_image()\n",
    "        image = image.resize((1000,1000))\n",
    "        cv2.imshow(\"image\",np.array(image))\n",
    "        cv2.waitKey(1)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjqrxI5rr3s_"
   },
   "outputs": [],
   "source": [
    "class DQNAgent:\n",
    "    def __init__(self):\n",
    "        # main model\n",
    "        self.main_model = self.create_model()\n",
    "        \n",
    "        # target model\n",
    "        self.target_model = self.create_model()\n",
    "        self.target_model.set_weights(self.main_model.get_weights())\n",
    "\n",
    "        # an array with last n steps for training\n",
    "        self.replay_memory = deque(maxlen=considering_training_length)\n",
    "\n",
    "        # used to know when to update target n/w with main n/w's weights\n",
    "        self.target_update_counter = 0\n",
    "        \n",
    "    def create_model(self):\n",
    "        model = Sequential()\n",
    "\n",
    "        # model.add(Conv2D(256, (10,10), input_shape=environment.observation_space))\n",
    "        model.add(Conv2D(256, (3,3), input_shape=environment.observation_space))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # model.add(Conv2D(256,(10,10)))\n",
    "        model.add(Conv2D(256,(3,3)))\n",
    "        model.add(Activation('relu'))\n",
    "        # model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(Dropout(0.2))\n",
    "\n",
    "        # converting the 3D features into the 1D feature\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(64))\n",
    "\n",
    "        model.add(Dense(environment.action_space, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer='Adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    # adding the step data into the array to be considered later\n",
    "    def update_replay_memory(self, step):\n",
    "        self.replay_memory.append(step)\n",
    "    \n",
    "    def train(self, terminal_state, step):\n",
    "        # start training only when we have a certain number of samples already saved\n",
    "        if len(self.replay_memory)< min_replay_memory_size:\n",
    "            return\n",
    "        # get the minibatch of the samples from the replay table\n",
    "        minibatch = random.sample(self.replay_memory, min_training_length)\n",
    "\n",
    "        # get current states from minibatch, then query NN model for Q values\n",
    "        current_states = np.array([transition[0] for transition in minibatch])/255\n",
    "        current_qs_list = self.main_model.predict(current_states)\n",
    "\n",
    "        # get future states from the minibatch, then query NN model for Q values\n",
    "        new_current_states = np.array([transition[3] for transition in minibatch])/255\n",
    "        future_qs_list = self.target_model.predict(new_current_states)\n",
    "\n",
    "        X = []\n",
    "        y = []\n",
    "        \n",
    "        # enumerating through the batches\n",
    "        for index,(current_state, action, reward, new_current_state, done) in enumerate(minibatch):\n",
    "            # if its not a terminal state, get new q from future states or else set to 0\n",
    "            if not done:\n",
    "                max_future_q = np.max(future_qs_list[index])\n",
    "                new_q = reward + discount*max_future_q\n",
    "            else:\n",
    "                new_q = reward\n",
    "\n",
    "            # update the q value for given state\n",
    "            current_qs = current_qs_list[index]\n",
    "            current_qs[action] = new_q\n",
    "\n",
    "            # append to the training data\n",
    "            X.append(current_state)\n",
    "            y.append(current_qs)\n",
    "        \n",
    "        # fit on all samples as one batch\n",
    "        self.main_model.fit(np.array(X)/255, np.array(y), batch_size=min_training_length, verbose=0, shuffle=False, callbacks=[LearningRateReducerCb()])\n",
    "        \n",
    "        # updating the target n/w counter every episode\n",
    "        if terminal_state:\n",
    "            self.target_update_counter += 1\n",
    "        \n",
    "        # if the counter reaches the required value...\n",
    "        # update the target n/w with weights of main n/w\n",
    "        if self.target_update_counter > update_target_every:\n",
    "            self.target_model.set_weights(self.main_model.get_weights())\n",
    "            self.target_update_counter = 0\n",
    "    \n",
    "    # query the main n/w for q values given the current observation space\n",
    "    def get_qs(self, state):\n",
    "        return self.main_model.predict(np.array(state).reshape(-1, *state.shape)/255)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = VRPEnvironment()\n",
    "agent = DQNAgent()\n",
    "# model related constants\n",
    "discount = 0.99 #the discount applied to the DQN equation\n",
    "# the environment keeps running till the demand of the nodes is satisfied\n",
    "considering_training_length = 50_000 #the no of steps considered for training\n",
    "min_training_length = 100 #the no of steps used for training\n",
    "# episodes = 30_000\n",
    "update_target_every = 5 #terminal states (end of episodes)\n",
    "min_replay_memory_size = 1000 #min no of steps in a memory to start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bb223c95saFs",
    "outputId": "f5525649-01fb-4d00-8df6-0a5ffe528010"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                             | 0/30000 [00:00<?, ?episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                                                                                                                                   | 14/30000 [00:00<03:48, 131.15episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|1                                                                                                                                                                   | 20/30000 [00:00<05:54, 84.60episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|1                                                                                                                                                                   | 25/30000 [00:00<07:23, 67.58episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "***Satisfied***\n",
      "\n",
      "***Satisfied***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|1                                                                                                                                                                   | 33/30000 [00:00<07:42, 64.75episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|1                                                                                                                                                                   | 33/30000 [00:12<07:42, 64.75episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|2                                                                                                                                                                 | 38/30000 [00:14<7:06:59,  1.17episodes/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|2                                                                                                                                                                | 39/30000 [00:18<15:32:21,  1.87s/episodes]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|2                                                                                                                                                                | 40/30000 [00:22<20:07:57,  2.42s/episodes]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-02961942efdc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[1;31m# Every step we update replay memory and train main network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_replay_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m         \u001b[0mcurrent_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-57-2e3aa745a8b8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, terminal_state, step)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# fit on all samples as one batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_training_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mLearningRateReducerCb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# updating the target n/w counter every episode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    591\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    594\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    704\u001b[0m       \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m       \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m       use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1613\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1614\u001b[0m     \"\"\"\n\u001b[1;32m-> 1615\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1617\u001b[0m   def interleave(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   3956\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3957\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[1;32m-> 3958\u001b[1;33m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[0;32m   3959\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3960\u001b[0m       raise TypeError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3145\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3146\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3147\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_concrete_function_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2393\u001b[0m     \u001b[1;34m\"\"\"Bypasses error checking when getting a graph function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2394\u001b[0m     graph_function = self._get_concrete_function_internal_garbage_collected(\n\u001b[1;32m-> 2395\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2396\u001b[0m     \u001b[1;31m# We're returning this concrete function to someone, and they may keep a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m     \u001b[1;31m# reference to the FuncGraph without keeping a reference to the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2388\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2389\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2390\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2703\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2705\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2593\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2595\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    976\u001b[0m                                           converted_func)\n\u001b[0;32m    977\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mwrapper_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3138\u001b[0m           attributes=defun_kwargs)\n\u001b[0;32m   3139\u001b[0m       \u001b[1;32mdef\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3140\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_wrapper_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3141\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3142\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m_wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   3080\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m       \u001b[1;31m# If `func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m       \u001b[1;31m# `ops.convert_to_tensor()` would conspire to attempt to stack\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m           optional_features=optional_features)\n\u001b[0;32m    233\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_whitelisted_for_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 459\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    460\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m   \u001b[1;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    328\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 330\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    331\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    342\u001b[0m           first_k_indices, [num_full_batches, batch_size])\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 344\u001b[1;33m       \u001b[0mflat_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDatasetV2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_k_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    345\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_partial_batch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         index_remainder = dataset_ops.DatasetV2.from_tensors(array_ops.slice(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    642\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m     \"\"\"\n\u001b[1;32m--> 644\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m   \u001b[1;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   2796\u001b[0m     variant_tensor = gen_dataset_ops.tensor_slice_dataset(\n\u001b[0;32m   2797\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2798\u001b[1;33m         output_shapes=structure.get_flat_tensor_shapes(self._structure))\n\u001b[0m\u001b[0;32m   2799\u001b[0m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTensorSliceDataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mtensor_slice_dataset\u001b[1;34m(components, output_shapes, name)\u001b[0m\n\u001b[0;32m   5675\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m   5676\u001b[0m         \u001b[1;34m\"TensorSliceDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomponents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomponents\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5677\u001b[1;33m                               output_shapes=output_shapes, name=name)\n\u001b[0m\u001b[0;32m   5678\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5679\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 742\u001b[1;33m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3320\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3321\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3322\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3323\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3324\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1784\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1785\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1786\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1787\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\capstone\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1594\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m   op_desc = c_api.TF_NewOperation(graph._c_graph, compat.as_str(node_def.op),\n\u001b[1;32m-> 1596\u001b[1;33m                                   compat.as_str(node_def.name))\n\u001b[0m\u001b[0;32m   1597\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1598\u001b[0m     \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_SetDevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "show_preview = False #using this will make it slow. Don't care about this now.\n",
    "aggregrate_stats_every = 50\n",
    "start_decaying = True #making this True ignores the conditional decaying - Notes 2.a\n",
    "\n",
    "x_axis = list(range(30001))\n",
    "epsilon_list = []\n",
    "rewards_list = []\n",
    "path_length_list = []\n",
    "\n",
    "k = 3000\n",
    "\n",
    "# iterate over the episodes\n",
    "for episode in tqdm(range(1, environment.no_of_episodes + 1), ascii=True, unit='episodes'):\n",
    "    #print(episode)\n",
    "    # Restarting episode - reset episode reward and step number\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "    # Reset environment and get initial state\n",
    "    current_state = environment.reset_environment()\n",
    "    # Reset flag and start iterating until episode ends\n",
    "    done = False\n",
    "    while not done:\n",
    "        # This part stays mostly the same, the change is to query a model for Q values\n",
    "        if np.random.random() > environment.epsilon:\n",
    "            # Get action from Q table\n",
    "            action = np.argmax(agent.get_qs(current_state))\n",
    "            #print(\"action=\"+str(action)+\"\\n++++++\")\n",
    "        else:\n",
    "            # Get random action\n",
    "            action = np.random.randint(1, environment.action_space)\n",
    "\n",
    "        if action != 0: #JUST IGNORING 0. MIGHT BE STUPID!\n",
    "            new_state, reward, done, completed = environment.step(action)\n",
    "        # Transform new continous state to new discrete state and count reward\n",
    "        episode_reward += reward\n",
    "        if show_preview and not episode % aggregrate_stats_every:\n",
    "            env.render()\n",
    "        # Every step we update replay memory and train main network\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "        agent.train(done, step)\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "\n",
    "        # Decay the Epsilon\n",
    "        if completed:\n",
    "            start_decaying = True\n",
    "        \n",
    "        if start_decaying:\n",
    "            # environment.epsilon = 0.001\n",
    "            if environment.epsilon > environment.min_epsilon:\n",
    "                # environment.epsilon *= environment.epsilon_decay\n",
    "                environment.epsilon = np.exp(-episode/k)\n",
    "                environment.epsilon = max(environment.min_epsilon, environment.epsilon)\n",
    "        # print(\".\",end=\"\")\n",
    "    epsilon_list.append(environment.epsilon)\n",
    "    rewards_list.append(episode_reward)\n",
    "    path_length_list.append(len(environment.truck.path))\n",
    "    \n",
    "print(\"Path is:\", end=\" \")\n",
    "print(environment.truck.path, end=\";\")\n",
    "print(\"P and R: \"+str(episode_reward), end=\";\")\n",
    "print(\"Capacity: \"+str(environment.truck.capacity), end=\";\")\n",
    "print(\"Epsilon: \"+str(environment.epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WBaJVfaDzf5x"
   },
   "outputs": [],
   "source": [
    "# # problem = tsplib95.load_problem('/content/drive/My Drive/HW Assignments/Sem 2/ADBI/Vrp-All/A/A-n32-k5.vrp')\n",
    "# problem = tsplib95.load_problem('/content/drive/My Drive/HW Assignments/Sem 2/ADBI/Vrp-All/_singleTruck/A-n32-k5_2.vrp')\n",
    "# nx_graph = problem.get_graph()\n",
    "# edge_list = list(problem.get_edges()) #[(,)]N\n",
    "# node_positions = problem.node_coords #dict\n",
    "# node_demands = copy.deepcopy(problem.demands)\n",
    "# truck_capacity = problem.capacity\n",
    "# Try rewarding for each node too i.e incentivize hopping!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWLdEBhZLRuR"
   },
   "outputs": [],
   "source": [
    "# node_demands[7] = 0\n",
    "# print(node_demands)\n",
    "# print(problem.demands)\n",
    "# print(sum(list(node_demands.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K1u2PzUxLYsO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x23a164f0cf8>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = list(range(10000))\n",
    "# print(x)\n",
    "k = 1000\n",
    "y = [float(np.exp(-i/k)) for i in x]\n",
    "# print(y)\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_axis,epsilon_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_axis,rewards_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x_axis,path_length_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "vrp_dqn_update.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
